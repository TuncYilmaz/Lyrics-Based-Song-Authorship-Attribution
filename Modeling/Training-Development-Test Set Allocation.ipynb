{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start by importing the appropriate pickle files to storing them in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def writePickle( Variable, fname):\n",
    "    filename = fname +\".pkl\"\n",
    "    f = open(\"pickle_vars/\"+filename, 'wb')\n",
    "    pickle.dump(Variable, f)\n",
    "    f.close()\n",
    "def readPickle(fname):\n",
    "    filename = \"pickle_vars/\"+fname +\".pkl\"\n",
    "    f = open(filename, 'rb')\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_dataset = readPickle(\"final_constrained_artist2idlist_dict\") # this is a dataset mapping each artist to a list of selected song IDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using numpy, we split the dataset into a X%-Y%-Z% partition, X, Y and Z indicating the percentages of the Training, Development and Test sets respectively\n",
    "#### Following Fell (2018) - Lyrics Segmentation, we follow a 60 - 20 - 20 split, but the function is flexible future changes\n",
    "#### In this version, we made a 13/15 (~86%) - 1/15 - 1/15 split to make the training set as big as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we're taking the combined_dataset and shuffling the lists to create a level of randomness\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "shuffled_combined_dataset = dict()\n",
    "for artist, id_list in combined_dataset.items():\n",
    "    copy_id_list = list(id_list)\n",
    "    shuffled_id_list = random.sample(copy_id_list, len(copy_id_list))    \n",
    "    shuffled_combined_dataset[artist] = shuffled_id_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then we'll use the shuffled dictionary to create a pandas dataframe\n",
    "import pandas as pd\n",
    "combined_dataframe = pd.DataFrame.from_dict(shuffled_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finally using numpy, we split the dataset. please change the parameters to obtain splits with different ratios\n",
    "import numpy as np\n",
    "\n",
    "train_df, dev_df, test_df = np.split(combined_dataframe.sample(frac=1), [int((13/15)*len(combined_dataframe)), int((14/15)*len(combined_dataframe))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examples\n",
    "print(train_df[['ABBA','Metallica']])\n",
    "print(dev_df[['ABBA','Metallica']])\n",
    "print(test_df[['ABBA','Metallica']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store each dataframe into pickle variables\n",
    "writePickle(combined_dataframe, \"combined_df\")\n",
    "writePickle(train_df, \"train_df\")\n",
    "writePickle(dev_df, \"dev_df\")\n",
    "writePickle(test_df, \"test_df\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
