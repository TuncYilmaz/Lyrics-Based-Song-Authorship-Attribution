{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Model Evaluation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def readPicklefromTraining(fname):\n",
    "    filename = \"Model_Training/pickle_vars/\"+fname +\".pkl\"\n",
    "    f = open(filename, 'rb')\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the model predictions that you want to evaluate\n",
    "pos_res = readPicklefromTraining(\"predictions_POS_33\") # one POS model\n",
    "pho_res = readPicklefromTraining(\"predictions_PHO1\") # one Phoneme Model\n",
    "rid_res = readPicklefromTraining(\"predictions_RID_33\") # one RID model\n",
    "dummy_res = readPicklefromTraining(\"predictions_dummy_33\") # and the dummy model\n",
    "\n",
    "# import the test labels for comparison\n",
    "test_labels = readPickle(\"cnn_data_inputs/test_POS_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each of the predicted labels in the model predictions, make a comparison with the actual test label counterpart \n",
    "import numpy as np\n",
    "PHO_correct_prediction_indices = list()\n",
    "test_label_list = test_labels\n",
    "counter = 0\n",
    "PHO_predict_array = []\n",
    "for array, label in zip(pho_res, test_labels):\n",
    "    predict = np.argmax(array, axis=None)\n",
    "    if predict == label: # the prediction matches the true value, add 1 to the prediction array for that model\n",
    "        PHO_correct_prediction_indices.append(test_label_list.index(label))\n",
    "        counter += 1\n",
    "        PHO_predict_array.append(1) \n",
    "    else: # if not, add a 0\n",
    "        PHO_predict_array.append(0)\n",
    "        \n",
    "print(counter)\n",
    "print(\"Total percentage of accurate labels in the test set is\", \"{0:.2%}\".format(counter/len(test_labels)), \"for the PHO model\")\n",
    "\n",
    "POS_correct_prediction_indices = list()\n",
    "test_label_list = test_labels\n",
    "counter = 0\n",
    "POS_predict_array = []\n",
    "for array, label in zip(pos_res, test_labels):\n",
    "    predict = np.argmax(array, axis=None)\n",
    "    if predict == label: # the prediction matches the true value, add 1 to the prediction array for that model\n",
    "        POS_correct_prediction_indices.append(test_label_list.index(label))\n",
    "        counter += 1\n",
    "        POS_predict_array.append(1)\n",
    "    else: # if not, add a 0\n",
    "        POS_predict_array.append(0)\n",
    "print(counter)\n",
    "print(\"Total percentage of accurate labels in the test set is\", \"{0:.2%}\".format(counter/len(test_labels)), \"for the POS model\")\n",
    "\n",
    "RID_correct_prediction_indices = list()\n",
    "test_label_list = test_labels\n",
    "counter = 0\n",
    "RID_predict_array = []\n",
    "for array, label in zip(rid_res, test_labels):\n",
    "    predict = np.argmax(array, axis=None)\n",
    "    if predict == label: # the prediction matches the true value, add 1 to the prediction array for that model\n",
    "        RID_correct_prediction_indices.append(test_label_list.index(label))\n",
    "        counter += 1\n",
    "        RID_predict_array.append(1)\n",
    "    else: # if not, add a 0\n",
    "        RID_predict_array.append(0)\n",
    "        \n",
    "print(counter)\n",
    "print(\"Total percentage of accurate labels in the test set is\", \"{0:.2%}\".format(counter/len(test_labels)), \"for the RID model\")\n",
    "\n",
    "\n",
    "dummy_correct_prediction_indices = list()\n",
    "test_label_list = test_labels\n",
    "counter = 0\n",
    "dummy_predict_array = []\n",
    "for array, label in zip(dummy_res, test_labels):\n",
    "    predict = np.argmax(array, axis=None)\n",
    "    if predict == label: # the prediction matches the true value, add 1 to the prediction array for that model\n",
    "        dummy_correct_prediction_indices.append(test_label_list.index(label))\n",
    "        counter += 1\n",
    "        dummy_predict_array.append(1)\n",
    "    else: # if not, add a 0\n",
    "        dummy_predict_array.append(0)\n",
    "        \n",
    "print(counter)\n",
    "print(\"Total percentage of accurate labels in the test set is\", \"{0:.2%}\".format(counter/len(test_labels)), \"for the dummy model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "429 correct labels<br>\n",
    "Total percentage of accurate labels in the test set is 9.41% for the PHO model<br>\n",
    "1383 correct labels<br>\n",
    "Total percentage of accurate labels in the test set is 30.33% for the POS model <br>\n",
    "1345 correct labels<br>\n",
    "Total percentage of accurate labels in the test set is 29.50% for the RID model<br>\n",
    "1340 correct labels<br>\n",
    "Total percentage of accurate labels in the test set is 29.39% for the dummy model<br>\n",
    "### By changing the predictions in the second cell, we can evaluate the scores of each individiual model. These predictions are used as examples here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using the following script, we can also add different models and see how their combinations work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_predict_array = []\n",
    "# for an example, combine the given Pho, POS and RID models\n",
    "for pho, pos, rid in zip(PHO_predict_array, POS_predict_array, RID_predict_array):\n",
    "    if pho == 1 or pos == 1 or rid == 1: # when any of the predictions are correct, count as one\n",
    "        combined_predict_array.append(1)\n",
    "    else:\n",
    "        combined_predict_array.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Total percentage of accurate labels in the test set is\", \"{0:.2%}\".format(combined_predict_array.count(1)/len(test_labels)), \"for the combined predictions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total percentage of accurate labels in the test set is 32.08% for the combined predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Predictions, Confusion Matrices, Training Loss/Accuracy Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def writePickle( Variable, fname):\n",
    "    filename = fname +\".pkl\"\n",
    "    f = open(\"pickle_vars/\"+filename, 'wb')\n",
    "    pickle.dump(Variable, f, protocol=4)\n",
    "    f.close()\n",
    "def readPickle(fname):\n",
    "    filename = \"pickle_vars/\"+fname +\".pkl\" # notice the ../ addition to reach out to variables from the parent directory\n",
    "    f = open(filename, 'rb')\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj\n",
    "def readHistory(fname):\n",
    "    filename = \"Model_Training/pickle_vars/\"+fname +\".pkl\" # notice the ../ addition to reach out to variables from the parent directory\n",
    "    f = open(filename, 'rb')\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj\n",
    "def readPicklefromTraining(fname):\n",
    "    filename = \"Model_Training/pickle_vars/\"+fname +\".pkl\"\n",
    "    f = open(filename, 'rb')\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a mapping dictionary to map each genre to one of the desired genre classes\n",
    "genre_mapping = {\"Folk Rock\" : \"Rock\", \"Soft Rock\" : \"Rock\", \"Britpop\": \"Pop\", \"Black Metal\": \"Metal\", \\\n",
    "                 \"Classic Rock\": \"Rock\",  'Dance-Pop' : 'Pop', 'Electro': 'Electronic', \"Post-Rock\": \"Rock\", \\\n",
    "                \"Power Pop\" : \"Pop\", \"Rock 'N' Roll\" : \"Rock\", 'Psychedelic Rock': \"Rock\",'Thrash Metal':\"Metal\",\\\n",
    "                 'American Folk': 'Folk', 'Dream Pop': 'Pop', 'Art Rock':'Rock', 'Reggae': 'Reggae',\\\n",
    "                 'Indie Folk': 'Folk', 'Jazz': \"Jazz & Blues\", 'Death Metal': \"Metal\", 'Progressive Rock': 'Rock',\\\n",
    "                 'Pop Rock': 'Pop', 'Electronic':'Electronic', 'Hard Rock':'Rock', 'R&B': 'R&B', 'Indie Pop':'Pop',\\\n",
    "                 'Heavy Metal':'Metal', 'Blues': \"Jazz & Blues\", 'Folk': \"Folk\", 'Country': 'Country', \\\n",
    "                 'Indie Rock':'Rock', 'Hip Hop': 'Hip Hop & Rap', 'Alternative Rock':'Rock', 'Rock':'Rock', 'Pop':'Pop' }\n",
    "\n",
    "id2Artists = readPickle(\"indexing/id2Artist\")\n",
    "Artists2genres = readPickle(\"artist_to_genre\")\n",
    "test_labels = readPickle(\"cnn_data_inputs/test_POS_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a function for genre mapping\n",
    "genre_test_labels = list()\n",
    "genre_test_labels_MAPPED = list()\n",
    "for ids in test_labels:\n",
    "    genre_test_labels.append(Artists2genres[id2Artists[ids]])\n",
    "    genre_test_labels_MAPPED.append(genre_mapping[Artists2genres[id2Artists[ids]]])\n",
    "\n",
    "def genre_checker(predictions):\n",
    "    all_genre_predictions = list()\n",
    "    all_MAPPED_genre_predictions = list()\n",
    "    for array in predictions: # here we need to write whatever prediction list we need to analyze\n",
    "        predict = np.argmax(array, axis=None)\n",
    "        all_genre_predictions.append(Artists2genres[id2Artists[predict]])\n",
    "        all_MAPPED_genre_predictions.append(genre_mapping[Artists2genres[id2Artists[predict]]])\n",
    "\n",
    "    total_count = 0\n",
    "    total_mapped_count = 0\n",
    "    correct_count = 0\n",
    "    correct_mapped_count = 0\n",
    "    for real_genre, predicted_genre in zip(genre_test_labels, all_genre_predictions):\n",
    "        total_count += 1\n",
    "        if real_genre == predicted_genre:\n",
    "            correct_count +=1\n",
    "    for real_genre, predicted_mapped_genre in zip(genre_test_labels_MAPPED, all_MAPPED_genre_predictions):\n",
    "        total_mapped_count += 1\n",
    "        if real_genre == predicted_mapped_genre:\n",
    "            correct_mapped_count += 1\n",
    "    print(\"Unmapped genre prediction accuracy for this prediction set is\", correct_count/total_count, \\\n",
    "          \"\\n while the mapped genre prediction accuracy for the same prediction set is\", correct_mapped_count/total_mapped_count)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use another function for genre confusion matrix\n",
    "genre_test_labels_set = list(set(genre_test_labels_MAPPED))\n",
    "genre_indexing = {v: k for v, k in enumerate(genre_test_labels_set)}\n",
    "\n",
    "def confusion_matrix(predictions):\n",
    "    \n",
    "    for ids in test_labels:\n",
    "        genre_test_labels_MAPPED.append(genre_mapping[Artists2genres[id2Artists[ids]]])\n",
    "    all_MAPPED_genre_predictions = list()\n",
    "    for array in predictions: # here we need to write whatever prediction list we need to analyze\n",
    "        predict = np.argmax(array, axis=None)\n",
    "        all_MAPPED_genre_predictions.append(genre_mapping[Artists2genres[id2Artists[predict]]])\n",
    "    \n",
    "    confusion_dict = dict()\n",
    "    for genre in genre_test_labels_set:\n",
    "        inter_dict = dict()\n",
    "        for item in genre_test_labels_set:\n",
    "            inter_dict[item] = 0\n",
    "        confusion_dict[genre] = inter_dict\n",
    "    for actual, predicted in zip(genre_test_labels_MAPPED, all_MAPPED_genre_predictions):\n",
    "        confusion_dict[actual][predicted] += 1\n",
    "    \n",
    "    cfm = pd.DataFrame(columns=genre_test_labels_set)\n",
    "    for genre in genre_test_labels_set:\n",
    "        cfm = cfm.append(confusion_dict[genre], ignore_index=True)\n",
    "    cfm_new = cfm.rename(genre_indexing)\n",
    "    \n",
    "    f1_score_dict = dict()\n",
    "    for genre in confusion_dict.keys():\n",
    "        TP = confusion_dict[genre][genre]\n",
    "        total_actuals = 0\n",
    "        for value in confusion_dict[genre].values():\n",
    "            total_actuals += value\n",
    "        FN = total_actuals - TP\n",
    "        total_predictions = 0\n",
    "        everything = 0\n",
    "        for genre2 in confusion_dict.keys():\n",
    "            total_predictions += confusion_dict[genre2][genre]\n",
    "            everything += sum(list(confusion_dict[genre2].values()))\n",
    "        FP = total_predictions - TP\n",
    "        TN = everything - (TP+FP+FN)\n",
    "        try:\n",
    "            Precision = TP/(TP+FP)\n",
    "        except:\n",
    "            Precision = 0\n",
    "        Recall = TP/(TP+FN)\n",
    "        print(genre, Precision, Recall)\n",
    "        try:\n",
    "            f1_score_dict[genre] = (2*Precision*Recall)/(Precision+Recall)\n",
    "        except:\n",
    "            f1_score_dict[genre] = 0.01\n",
    "    average_f1_score = sum(list(f1_score_dict.values()))/10\n",
    "    \n",
    "\n",
    "    #confusion_matrix_perc.loc['Column_Total']= confusion_matrix_perc.sum(numeric_only=True, axis=0)\n",
    "    #confusion_matrix_perc.loc[:,'Row_Total'] = confusion_matrix_perc.sum(numeric_only=True, axis=1)\n",
    "    return cfm_new, f1_score_dict, average_f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the best POS model that overfits (but not the worst overfitting model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = readPickle(\"cnn_data_inputs/test_POS_labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = readHistory(\"history_POS_25ep_128bch_05Drop_33filter_batchnorm\")\n",
    "model_predictions = readPicklefromTraining(\"predictions_POS_25ep_128bch_05Drop_33filter_batchnorm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "POS_correct_prediction_indices = list()\n",
    "test_label_list = test_labels\n",
    "counter = 0\n",
    "POS_predict_array = []\n",
    "for array, label in zip(model_predictions, test_labels):\n",
    "    predict = np.argmax(array, axis=None)\n",
    "    if predict == label:\n",
    "        POS_correct_prediction_indices.append(test_label_list.index(label))\n",
    "        counter += 1\n",
    "        POS_predict_array.append(1)\n",
    "    else:\n",
    "        POS_predict_array.append(0)\n",
    "        \n",
    "print(counter)\n",
    "print(\"Total percentage of accurate labels in the test set is\", \"{0:.2%}\".format(counter/len(test_labels)), \"for the PHO model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "\n",
    "fig.suptitle('POS ONLY MODEL WITH NO SIZE RESTRICTIONS')\n",
    "\n",
    "    \n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "ax1.plot(epochs, loss, color='red', label='Training loss')\n",
    "ax1.plot(epochs, val_loss, color='green', label='Validation loss')\n",
    "ax1.set(ylabel=\"Loss\")\n",
    "ax1.legend()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "ax2.plot(epochs, acc, color='red', label='Training acc')\n",
    "ax2.plot(epochs, val_acc, color='green', label='Validation acc')\n",
    "ax2.set(xlabel = \"Number of Epochs\", ylabel=\"Accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_checker(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The average f1 score for this genre prediction model is:\", confusion_matrix(model_predictions)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 10_10 (Reduced) Pho Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = readHistory(\"history_PHO_10_10_25ep_64bch_05Drop_33filter_batchnorm\")\n",
    "model_predictions = readPicklefromTraining(\"predictions_PHO_10_10_batchnorm_25ep_64bch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "\n",
    "fig.suptitle('PHO ONLY MODEL WITH (10,10) SIZE RESTRICTIONS')\n",
    "\n",
    "    \n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "ax1.plot(epochs, loss, color='red', label='Training loss')\n",
    "ax1.plot(epochs, val_loss, color='green', label='Validation loss')\n",
    "ax1.set(ylabel=\"Loss\")\n",
    "ax1.legend()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "ax2.plot(epochs, acc, color='red', label='Training acc')\n",
    "ax2.plot(epochs, val_acc, color='green', label='Validation acc')\n",
    "ax2.set(xlabel = \"Number of Epochs\", ylabel=\"Accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_checker(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The average f1 score for this genre prediction model is:\", confusion_matrix(model_predictions)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â RID_Reduced (10,3) Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = readHistory(\"history_RID_reduced_25ep_64bch_05Drop_11filter_batchnorm\")\n",
    "model_predictions = readPicklefromTraining(\"predictions_RID_reduced_batchnorm_25ep_64bch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "\n",
    "fig.suptitle('RID ONLY MODEL WITH (10,3) SIZE RESTRICTIONS')\n",
    "\n",
    "    \n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "ax1.plot(epochs, loss, color='red', label='Training loss')\n",
    "ax1.plot(epochs, val_loss, color='green', label='Validation loss')\n",
    "ax1.set(ylabel=\"Loss\")\n",
    "ax1.legend()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "ax2.plot(epochs, acc, color='red', label='Training acc')\n",
    "ax2.plot(epochs, val_acc, color='green', label='Validation acc')\n",
    "ax2.set(xlabel = \"Number of Epochs\", ylabel=\"Accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_checker(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The average f1 score for this genre prediction model is:\", confusion_matrix(model_predictions)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct genre predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different POS models (reduced and full respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_predictions = readPicklefromTraining(\"predictions_POS_GENRE_reduced_batchnorm_25ep_64bch\")\n",
    "print(confusion_matrix(model_predictions)[1], confusion_matrix(model_predictions)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_predictions = readPicklefromTraining(\"predictions_POS_GENRE_25ep_128bch_05Drop_33filter_batchnorm\")\n",
    "print(confusion_matrix(model_predictions)[1], confusion_matrix(model_predictions)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduced PHO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_predictions = readPicklefromTraining(\"predictions_PHO_GENRE_10_10_batchnorm_25ep_64bch\")\n",
    "print(confusion_matrix(model_predictions)[1], confusion_matrix(model_predictions)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model_predictions)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduced RID model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_predictions = readPicklefromTraining(\"predictions_RID_GENRE_reduced_batchnorm_25ep_64bch\")\n",
    "print(confusion_matrix(model_predictions)[1], confusion_matrix(model_predictions)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis for Certain Phoneme Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_to_PHO = readPickle(\"ids2splitted_phonemes_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "for song_id in list(ID_to_PHO.keys())[0:20]:\n",
    "    song = ID_to_PHO[song_id]\n",
    "    all_song_phonemes = list()\n",
    "    for line in song:\n",
    "        refined_line = [tag for tag in line if tag != ' ' and tag != 'PADDING']\n",
    "        combined_line = ''.join(refined_line)\n",
    "        if len(combined_line) >= 3:\n",
    "            for i in range(len(combined_line)-3+1):\n",
    "                all_song_phonemes.append(combined_line[i:i+3])\n",
    "\n",
    "    all_phoneme_freq = defaultdict(int)\n",
    "    for pho in all_song_phonemes:\n",
    "        all_phoneme_freq[pho] += 1\n",
    "\n",
    "    sorted_all_phoneme_freq = OrderedDict(sorted(all_phoneme_freq.items(), key=lambda v: v[1], reverse=True))\n",
    "    refined_all_phoneme_freq = dict()\n",
    "    for pho, count in sorted_all_phoneme_freq.items():\n",
    "        if count > 1:\n",
    "            refined_all_phoneme_freq[pho] = count\n",
    "    refined_all_phoneme_freq = OrderedDict(sorted(refined_all_phoneme_freq.items(), key=lambda v: v[1], reverse=True))\n",
    "    print(\"Total percentage of phonemes that occur at least 2 times in the song is\", \"{0:.2%}\".format(len(refined_all_phoneme_freq)/len(sorted_all_phoneme_freq)))\n",
    "    print(\"The number of phonemes that occur at least 2 times in the song is:\", len(refined_all_phoneme_freq))\n",
    "    \n",
    "    plt.bar(refined_all_phoneme_freq.keys(), refined_all_phoneme_freq.values(), width=1, color='g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the songs generally consist of 3-gram phonemes that occur at least two times throughout the song, let's write a function that converts each song to phoneme n-grams, calculates their frequencies and assign values in terms of these frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def song_phoneme_freq(ngram): #ngram defines the number of phonetic signs that occur successively to form a basic rhytmical component\n",
    "    counter = 0\n",
    "    total_dataset_length = len(list(ID_to_PHO.keys()))\n",
    "    ID_to_Full_Rhymes = dict() #this one is for all phonemes, but assigning 0.0 to the ones that occur seldom (i.e less than two times in the song)\n",
    "    ID_to_Partial_Rhymes = dict() #this one is for phonemes that occur very frequently only\n",
    "    for song_id, song in ID_to_PHO.items():\n",
    "        counter += 1\n",
    "        print(counter, \"out of\", total_dataset_length, \"songs is being processed now\")\n",
    "        \n",
    "        # the first step is to find all n-gram phonetical representations and their frequencies in a song\n",
    "        all_song_phonemes = list()\n",
    "        for line in song:\n",
    "            refined_line = [tag for tag in line if tag != ' ' and tag != 'PADDING'] # first strip each line from blank spaces and paddings\n",
    "            combined_line = ''.join(refined_line) # combine phonetical representations\n",
    "            # create a list of n-gram phonetical representations \n",
    "            if len(combined_line) >= ngram:\n",
    "                for i in range(len(combined_line)-ngram+1):\n",
    "                    all_song_phonemes.append(combined_line[i:i+ngram])\n",
    "        all_phoneme_freq = defaultdict(int) # this is for counting and recording the frequencies\n",
    "        for pho in all_song_phonemes:\n",
    "            all_phoneme_freq[pho] +=1\n",
    "        sorted_all_phoneme_freq = OrderedDict(sorted(all_phoneme_freq.items(), key=lambda v: v[1], reverse=True)) # sort the frequencies in descending order\n",
    "        refined_all_phoneme_freq = dict()\n",
    "        for pho, count in sorted_all_phoneme_freq.items():\n",
    "            if count > 1:\n",
    "                refined_all_phoneme_freq[pho] = count\n",
    "        refined_all_phoneme_freq = OrderedDict(sorted(refined_all_phoneme_freq.items(), key=lambda v: v[1], reverse=True))\n",
    "        \n",
    "        # for the top 9 most frequently occuring n-gram phonemes, assign values 0.95, 0.9, 0.85, .... , 0.55 respectively\n",
    "        percentage_allocation = dict()\n",
    "        perc = 1.0\n",
    "        for phoneme in list(refined_all_phoneme_freq.keys())[0:9]:\n",
    "            perc -= 0.05\n",
    "            percentage_allocation[phoneme] = round(perc,1)\n",
    "        # if there are more phoneme n-grams with less frequencies (which is the case 99% of the time)\n",
    "        try: # assign 0.5 to the 10th most occuring phoneme n-gram frequency, and normalize the rest of the frequencies with respect to 0.5\n",
    "            max_rest_freq = refined_all_phoneme_freq[list(refined_all_phoneme_freq.keys())[9]]\n",
    "            for phoneme in list(refined_all_phoneme_freq.keys())[9:]:\n",
    "                percentage_allocation[phoneme] = round(refined_all_phoneme_freq[phoneme]/max_rest_freq*0.5,1)\n",
    "        except:\n",
    "            print(\"There are at most 8 phonemes in song with id\", song_id)\n",
    "        \n",
    "        # after mapping each n-gram phoneme to its respective normalized frequency value, \n",
    "        # we continue with converting the songs to these normalized values. \n",
    "        # one version assigns the value 0.0 also to the n-grams occuring less than 2 times, the other disregards them\n",
    "        converted_song_rhymes_only = list() # <2 n-grams are disregarded\n",
    "        converted_song_all_phonemes = list() # <2 n-grams are included and assigned 0.0\n",
    "        for line in song:\n",
    "            converted_line_rhymes_only = list()\n",
    "            converted_line_all_phonemes = list()\n",
    "            transformed_line = ''.join([tag for tag in line if tag != ' ' and tag != 'PADDING'])\n",
    "            if len(transformed_line) >= ngram:\n",
    "                for i in range(len(transformed_line)-ngram+1):\n",
    "                    try:\n",
    "                        converted_line_rhymes_only.append(percentage_allocation[transformed_line[i:i+ngram]])\n",
    "                        converted_line_all_phonemes.append(percentage_allocation[transformed_line[i:i+ngram]])\n",
    "                    except:\n",
    "                        converted_line_all_phonemes.append(0.0)\n",
    "            if len(converted_line_rhymes_only) > 0:\n",
    "                converted_song_rhymes_only.append(converted_line_rhymes_only)\n",
    "            if len(converted_line_all_phonemes) > 0:\n",
    "                converted_song_all_phonemes.append(converted_line_all_phonemes)\n",
    "        ID_to_Full_Rhymes[song_id] = converted_song_all_phonemes\n",
    "        ID_to_Partial_Rhymes[song_id] = converted_song_rhymes_only\n",
    "\n",
    "    return ID_to_Full_Rhymes, ID_to_Partial_Rhymes\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_to_Full_Rhymes, ID_to_Partial_Rhymes = song_phoneme_freq(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writePickle(ID_to_Full_Rhymes, \"ID_to_Full_Rhymes\")\n",
    "writePickle(ID_to_Partial_Rhymes, \"ID_to_Partial_Rhymes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to find some statistics about the line lengths and songs lengths of these phoneme n-gram frequency versions of songs. According to the statistics, we'll apply certain resizing operations to substitute masking in CNNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_length_counts_full = list()\n",
    "max_line_length_counts_full = list()\n",
    "song_length_counts_partial = list()\n",
    "max_line_length_counts_partial = list()\n",
    "for song in ID_to_Full_Rhymes.values():\n",
    "    song_length_counts_full.append(len(song))\n",
    "    line_length_counts = list()\n",
    "    for line in song:\n",
    "        line_length_counts.append(len(line))\n",
    "    max_line_length_counts_full.append(max(line_length_counts))\n",
    "for song in ID_to_Partial_Rhymes.values():\n",
    "    song_length_counts_partial.append(len(song))\n",
    "    line_length_counts = list()\n",
    "    for line in song:\n",
    "        line_length_counts.append(len(line))\n",
    "    max_line_length_counts_partial.append(max(line_length_counts))\n",
    "    \n",
    "from collections import OrderedDict\n",
    "\n",
    "# for full rhymes, form ordered dictionaries that map song lengths to their frequency of occuring in the whole dataset\n",
    "# also form another ordered dict for max line length frequencies\n",
    "full_song_length_freq = defaultdict(int)\n",
    "full_max_line_length_freq = defaultdict(int)\n",
    "for length in song_length_counts_full:\n",
    "    full_song_length_freq[length] += 1\n",
    "sorted_full_song_length_freq = OrderedDict(sorted(full_song_length_freq.items(), key=lambda v: v[0], reverse=False))\n",
    "for length in max_line_length_counts_full:\n",
    "    full_max_line_length_freq[length] += 1\n",
    "sorted_full_max_line_length_freq = OrderedDict(sorted(full_max_line_length_freq.items(), key=lambda v: v[0], reverse=False))\n",
    "# do the same for partial rhymes\n",
    "partial_song_length_freq = defaultdict(int)\n",
    "partial_max_line_length_freq = defaultdict(int)\n",
    "for length in song_length_counts_partial:\n",
    "    partial_song_length_freq[length] += 1\n",
    "sorted_partial_song_length_freq = OrderedDict(sorted(partial_song_length_freq.items(), key=lambda v: v[0], reverse=False))\n",
    "for length in max_line_length_counts_partial:\n",
    "    partial_max_line_length_freq[length] += 1\n",
    "sorted_partial_max_line_length_freq = OrderedDict(sorted(partial_max_line_length_freq.items(), key=lambda v: v[0], reverse=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = sorted_partial_song_length_freq\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 9))\n",
    "\n",
    "x = range(len(data))\n",
    "y = np.cumsum(list(data.values())).astype(\"float32\")\n",
    "y/=y.max()\n",
    "y*=100.\n",
    "#y = list(data.values())\n",
    "\n",
    "ax.bar(x, y, label=\"Cumulative Song Lengths\", fill=False)\n",
    "ax.axhline(y=80.0, color = \"r\")\n",
    "ax.axhline(y=60.0, color = \"b\")\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.xticks(x, data.keys(), rotation='vertical')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='center left')\n",
    "ax.set_title('Song Length Frequency Distrubition for Partial N-Gram Phonemes')\n",
    "ax.set_xlabel('Total Song Length in terms of Number of Lines')\n",
    "ax.set_ylabel('Percentage of songs that have at least x lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = sorted_partial_max_line_length_freq\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 9))\n",
    "\n",
    "x = range(len(data))\n",
    "y = np.cumsum(list(data.values())).astype(\"float32\")\n",
    "y/=y.max()\n",
    "y*=100.\n",
    "#y = list(data.values())\n",
    "\n",
    "ax.bar(x, y, label=\"Cumulative Max Line Lengths per Song\", fill=False)\n",
    "ax.axhline(y=80.0, color = \"r\")\n",
    "ax.axhline(y=60.0, color = \"b\")\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.xticks(x, data.keys(), rotation='vertical')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='center left')\n",
    "ax.set_title('Max Line Length per Song Frequency Distrubition for Partial N-Gram Phonemes')\n",
    "ax.set_xlabel('Total Max Line Length in terms of Number of Ngrams')\n",
    "ax.set_ylabel('Percentage of songs that have a line with at most x ngrams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = sorted_partial_song_length_freq\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 9))\n",
    "\n",
    "x = range(len(data))\n",
    "y = np.cumsum(list(data.values())).astype(\"float32\")\n",
    "y/=y.max()\n",
    "y*=100.\n",
    "#y = list(data.values())\n",
    "\n",
    "ax.bar(x, y, label=\"Cumulative Song Lengths\", fill=False)\n",
    "ax.axhline(y=80.0, color = \"r\")\n",
    "ax.axhline(y=60.0, color = \"b\")\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.xticks(x, data.keys(), rotation='vertical')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='center left')\n",
    "ax.set_title('Song Length Frequency Distrubition for Full N-Gram Phonemes')\n",
    "ax.set_xlabel('Total Song Length in terms of Number of Lines')\n",
    "ax.set_ylabel('Percentage of songs that have at least x lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = sorted_full_max_line_length_freq\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 9))\n",
    "\n",
    "x = range(len(data))\n",
    "y = np.cumsum(list(data.values())).astype(\"float32\")\n",
    "y/=y.max()\n",
    "y*=100.\n",
    "#y = list(data.values())\n",
    "\n",
    "ax.bar(x, y, label=\"Cumulative Max Line Lengths per Song\", fill=False)\n",
    "ax.axhline(y=80.0, color = \"r\")\n",
    "ax.axhline(y=60.0, color = \"b\")\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.xticks(x, data.keys(), rotation='vertical')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='center left')\n",
    "ax.set_title('Max Line Length per Song Frequency Distrubition for Full N-Gram Phonemes')\n",
    "ax.set_xlabel('Total Max Line Length in terms of Number of Ngrams')\n",
    "ax.set_ylabel('Percentage of songs that have a line with at most x ngrams')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
