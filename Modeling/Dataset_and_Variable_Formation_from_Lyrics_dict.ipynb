{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the first phase of the script we will form a subset of the complete dataset:\n",
    "- Prune genres that occur very seldom or that cannot be mapped to a more common genre\n",
    "- Detect non-English songs\n",
    "- Prune artists that has less than n songs and less than m non-English songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start by feeding your Pickle functions to call and save pickle variables later on\n",
    "\n",
    "import pickle\n",
    "def writePickle( Variable, fname):\n",
    "    filename = fname +\".pkl\"\n",
    "    f = open(\"pickle_vars/\"+filename, 'wb')\n",
    "    pickle.dump(Variable, f)\n",
    "    f.close()\n",
    "def readPickle(fname):\n",
    "    filename = \"pickle_vars/\"+fname +\".pkl\"\n",
    "    f = open(filename, 'rb')\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj\n",
    "def readPicklefromPast(fname):\n",
    "    filename = \"../pickle_vars/\"+fname +\".pkl\"\n",
    "    f = open(filename, 'rb')\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyrics_dict = readPicklefromPast('lyrics_dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then get some of the necessary information existing in the whole dataset and group them in several dictionaries that consist of artists as the keys, and the information pieces as the values. Record these dictionaries as pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_to_lyrics = dict() # a dictionary mapping each artist to a list containing her songs\n",
    "artist_to_genre = dict() # a dictionary mapping each artist to the genre that is attributed to her the most\n",
    "artist_to_numberofsongs = dict() # a dictionary mapping the artist to the number of collected songs belonging to her\n",
    "artist_to_numberofalbums = dict() # a dictionary mapping the artist to the number of collected albums belonging to her\n",
    "artist_to_years = dict() # a dictionary mapping each artist to a list containing the years of each song that is collected from the website\n",
    "\n",
    "for artist, content in lyrics_dict.items():\n",
    "    artist_to_lyrics[artist] = []\n",
    "    artist_to_years[artist] = []\n",
    "    artist_to_genre[artist] = content[0]\n",
    "    artist_to_numberofsongs[artist] = content[-1]\n",
    "    artist_to_numberofalbums[artist] = content[-2]\n",
    "    for album in content[2].values():\n",
    "        for song in album[1].values():\n",
    "            artist_to_lyrics[artist].append(song[0])\n",
    "            artist_to_years[artist].append(song[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write all the subset dictionaries into pickle files\n",
    "writePickle(artist_to_lyrics, 'artist_to_lyrics')\n",
    "writePickle(artist_to_genre, 'artist_to_genre')\n",
    "writePickle(artist_to_numberofsongs, 'artist_to_numberofsongs')\n",
    "writePickle(artist_to_numberofalbums, 'artist_to_numberofalbums')\n",
    "writePickle(artist_to_years, 'artist_to_years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_count = 0\n",
    "for artist in artist_to_lyrics.keys():\n",
    "    song_count += artist_to_numberofsongs[artist]\n",
    "print(\"Now there are\", song_count, \"songs from\", len(list(artist_to_lyrics.keys())), \"artists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are 559987 songs from 6352 artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with pruning some of the artists that belong to genres that does not occur frequently in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_genres = list(set(artist_to_genre.values()))\n",
    "genre_to_numberofsongs = dict()\n",
    "genre_to_numberofalbums = dict()\n",
    "genre_to_numberofartists = dict()\n",
    "for genre in unique_genres:\n",
    "    genre_to_numberofsongs[genre] = 0\n",
    "    genre_to_numberofalbums[genre] = 0\n",
    "    genre_to_numberofartists[genre] = 0\n",
    "\n",
    "for artist, genre in artist_to_genre.items():\n",
    "    genre_to_numberofartists[genre] += 1\n",
    "    genre_to_numberofsongs[genre] += artist_to_numberofsongs[artist]\n",
    "    genre_to_numberofalbums[genre] += artist_to_numberofalbums[artist]\n",
    "    \n",
    "# get the dictionaries sorted:\n",
    "sorted_artists = sorted(genre_to_numberofartists.items(), key=lambda kv: kv[1])\n",
    "sorted_songs = sorted(genre_to_numberofsongs.items(), key=lambda kv: kv[1])\n",
    "sorted_albums = sorted(genre_to_numberofalbums.items(), key=lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "print(\"There are in total\", len(list(collections.OrderedDict(sorted_artists).items())), \"different genres detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before pruning, there are 440 different genres detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# partition all genre categories into genres that occur less than 11 times, and those that occur more than 10 times\n",
    "insufficient_genres = []\n",
    "sufficient_genres = []\n",
    "for item in art:\n",
    "    if item[1] < 11:\n",
    "        insufficient_genres.append(item[0])\n",
    "    else:\n",
    "        sufficient_genres.append(item[0])\n",
    "\n",
    "print(\"There are\",len(sufficient_genres), \"genres that occur at least 11 times in the whole dataset. \\\n",
    "These genres will be mapped into more comprehensive genre classes, or will be discarded in cases where the genre \\\n",
    "does not comply with our interests\")\n",
    "print(\"There are\",len(insufficient_genres),\"genres that occur less than 11 times in the whole dataset. \\\n",
    "These will be discarded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 40 genres that occur at least 11 times in the whole dataset. These genres will be mapped into more comprehensive genre classes, or will be discarded in cases where the genre does not comply with our interests\n",
    "There are 400 genres that occur less than 11 times in the whole dataset. These will be discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a mapping dictionary to map each genre to one of the desired genre classes\n",
    "genre_mapping = {\"Folk Rock\" : \"Rock\", \"Soft Rock\" : \"Rock\", \"Britpop\": \"Pop\", \"Black Metal\": \"Metal\", \\\n",
    "                 \"Classic Rock\": \"Rock\",  'Dance-Pop' : 'Pop', 'Electro': 'Electronic', \"Post-Rock\": \"Rock\", \\\n",
    "                \"Power Pop\" : \"Pop\", \"Rock 'N' Roll\" : \"Rock\", 'Psychedelic Rock': \"Rock\",'Thrash Metal':\"Metal\",\\\n",
    "                 'American Folk': 'Folk', 'Dream Pop': 'Pop', 'Art Rock':'Rock', 'Reggae': 'Reggae',\\\n",
    "                 'Indie Folk': 'Folk', 'Jazz': \"Jazz & Blues\", 'Death Metal': \"Metal\", 'Progressive Rock': 'Rock',\\\n",
    "                 'Pop Rock': 'Pop', 'Electronic':'Electronic', 'Hard Rock':'Rock', 'R&B': 'R&B', 'Indie Pop':'Pop',\\\n",
    "                 'Heavy Metal':'Metal', 'Blues': \"Jazz & Blues\", 'Folk': \"Folk\", 'Country': 'Country', \\\n",
    "                 'Indie Rock':'Rock', 'Hip Hop': 'Hip Hop & Rap', 'Alternative Rock':'Rock', 'Rock':'Rock', 'Pop':'Pop' }\n",
    "\n",
    "# some of the genres will be eliminated since they don't comply with our initial target genre categories\n",
    "uncategorized_genres = ['New Age', \"Ska Punk\", \"Beat\", 'Trip Hop', \"Experimental\", \"Funk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_pruned_artist_list = [] # this list will later on will be used to discard the artists \n",
    "                              # that belong to genres that occur very rarely or not classified\n",
    "for artist, genre in artist_to_genre.items():\n",
    "    if genre in insufficient_genres or genre in uncategorized_genres:\n",
    "        genre_pruned_artist_list.append(artist)\n",
    "    \n",
    "print(\"There are\", len(genre_pruned_artist_list), \"artists that will be pruned due to belonging to insufficient genres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 983 artists that will be pruned due to belonging to insufficient genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get all the songs in a dictionary by their ids if the artist of that song is not pruned by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_id_dict = dict()\n",
    "for artist in lyrics_dict.keys():\n",
    "    if artist not in genre_pruned_artist_list:\n",
    "        for value in lyrics_dict[artist][2].values():\n",
    "            for song in value[1].values():\n",
    "                lyrics = song[0]\n",
    "                s_id = song[3]\n",
    "                song_id_dict[s_id] = lyrics\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are 460498 songs that belong to any desired genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see an example of a sample song lyric\n",
    "song_id_dict['200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the dictionary that maps song_ids to lyrics into a pickle file for later use\n",
    "writePickle(song_id_dict, \"song_id_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use langdetect tool to spot songs that are not in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_english_song_ids = []\n",
    "from langdetect import detect\n",
    "for song_id, lyrics in song_id_dict.items():\n",
    "    try:\n",
    "        lang = detect(lyrics)\n",
    "        if lang != 'en':\n",
    "            non_english_song_ids.append(song_id)\n",
    "    except:\n",
    "        non_english_song_ids.append(song_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of a total of 460498 songs, 98278 are not classified as in English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also create a dictionary where keys are artists and values are a list of song ids that belong to each artist. Then using the non-English song ids list, find out how many songs of those artists are actually in English. If that value is below a certain threshold, remove that artist from the initial dataset, along with other non English songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_to_song_id = dict()\n",
    "for artist in lyrics_dict:\n",
    "    artist_to_song_id[artist] = []\n",
    "    if artist not in genre_pruned_artist_list:\n",
    "        for value in lyrics_dict[artist][2].values():\n",
    "            for song in value[1].values():\n",
    "                s_id = song[3]\n",
    "                artist_to_song_id[artist].append(s_id)\n",
    "                \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_and_english_song_ids = dict()\n",
    "replica = dict(artist_to_song_id)\n",
    "for artist, song_id_list in replica.items():\n",
    "    if len(song_id_list) < 150: # we first prune the artists that have less then n songs anyways\n",
    "        del artist_to_song_id[artist]\n",
    "        continue\n",
    "    else:\n",
    "        number_checker = []\n",
    "        for s_id in song_id_list:\n",
    "            if s_id not in non_english_song_ids:  \n",
    "                number_checker.append(s_id)\n",
    "        if len(number_checker) >= 150: # then we prune others that have less than m English songs\n",
    "            artists_and_english_song_ids[artist] = number_checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the non-English songs and artists, there are 147470 songs and 544 artists left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the pickle variables that are created in these steps\n",
    "writePickle(genre_pruned_artist_list, \"genre_pruned_artist_list\")\n",
    "writePickle(non_english_song_ids, \"non_english_song_ids\")\n",
    "writePickle(artist_to_song_id, \"artist_to_song_id\") # this one is for artists that have total songs above a threshold\n",
    "writePickle(artists_and_english_song_ids, \"artists_and_english_song_ids\") # this one is for artists that have total English songs above a threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the second phase, we will check each artist with her English song ids, and prune those artist that does not comply with several song length criteria. Some of the criteria are:\n",
    "- The number of lines in a song should not be more than m and less than l\n",
    "- The maximum number of tokens in a line should not be more than k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the previously formed pickle variable that maps each song id to its lyrics\n",
    "ids_to_lyrics_dict = readPicklefromPast(\"all_songids2_lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use spaCy english tokenizer and POS tagger \n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to time constraints, the following calculation will be carried out in a separate python script named 'Lyrics_size_constraints.py' and the resulting dictionary will be saved to a pickle file named \"size_constrained_artists_to_ids.pkl\". Please refer to that script that can be found in the same folder. You can also check the following cell to see the details of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "size_constrained_artists_to_ids = dict()\n",
    "for artist, song_list in artists_and_english_song_ids.items():\n",
    "    size_constrained_artists_to_ids[artist] = list()\n",
    "    for song_id in song_list:\n",
    "        counter +=1\n",
    "        print(counter)\n",
    "        lines = ids_to_lyrics_dict[song_id].split('<>')\n",
    "        # check whether the second line gives song writer info. if so, remove the first two lines\n",
    "        if lines[1][0:6] == 'Writer' or lines[1][0:7] == 'Writers':\n",
    "            lines = lines[2:]\n",
    "        song_length = len(lines)-1\n",
    "        # if the song_length is below 10 or above 100, ignore song and continue with the next one\n",
    "        if song_length < 10 or song_length > 100:\n",
    "            continue\n",
    "        else: # if the song length satisfies our constraints, continue checking the max line length\n",
    "            line_length_counter = []\n",
    "            for line in lines[:-1]: # because the last line is always blank in the dataset\n",
    "                doc = nlp(line)\n",
    "                tokens = []\n",
    "                for token in doc:\n",
    "                    tokens.append(token.text)\n",
    "                line_length_counter.append(len(tokens))\n",
    "        if max(line_length_counter) < 21: # as long as the max line length in a song is less than 21, add the song id\n",
    "            size_constrained_artists_to_ids[artist].append(song_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternatively import the dictionary formed in a separate script\n",
    "size_constrained_artists_to_ids = readPickle(\"size_constrained_artists_to_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally detect the artists with at least 150 songs in the collection, select randomly 150 of those songs per artist, and create the final selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "final_constrained_artist2idlist_dict = dict()\n",
    "for artist, song_list in size_constrained_artists_to_ids.items():\n",
    "    if len(song_list) >= 150:\n",
    "        randomized = random.shuffle(song_list)\n",
    "        final_constrained_artist2idlist_dict[artist] = song_list[0:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write it to a pickle file\n",
    "writePickle(final_constrained_artist2idlist_dict, \"final_constrained_artist2idlist_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, instead of mapping the artists to a list of song ids, map each artist to a list of her song lyrics, and store this dictionary into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_artist2lyrics_dict = dict()\n",
    "for artist, song_list in final_constrained_artist2idlist_dict.items():\n",
    "    lyrics_list = list()\n",
    "    for song_id in song_list:\n",
    "        lyrics_list.append(song_id_dict[song_id])\n",
    "    final_artist2lyrics_dict[artist] = lyrics_list\n",
    "\n",
    "writePickle(final_artist2lyrics_dict, \"final_artist2lyrics_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
